#!/usr/bin/env python3
"""
AIè³‡è¨Šé é¢è‡ªå‹•æ›´æ–°è…³æœ¬
"""

import os
import re
import json
import sys
import requests
from datetime import datetime, timedelta
from pathlib import Path

# è¨­å®šè·¯å¾‘
REPO_PATH = Path(__file__).parent.parent
AI_NEWS_FILE = REPO_PATH / "ai-news.html"

def fetch_ai_news():
    """ç²å–æœ€æ–°çš„AIæ–°èï¼ˆæ¨¡æ“¬åŠŸèƒ½ï¼‰"""
    
    print("ğŸ” ç²å–æœ€æ–°AIæ–°è...")
    
    # é€™è£¡å¯ä»¥å¯¦ç¾å¯¦éš›çš„æ–°èæŠ“å–åŠŸèƒ½
    # ä¾‹å¦‚ï¼šä½¿ç”¨RSSè¨‚é–±ã€æ–°èAPIã€ç¶²çµ¡çˆ¬èŸ²ç­‰
    
    # æ¨¡æ“¬ä¸€äº›AIæ–°è
    today = datetime.now()
    yesterday = today - timedelta(days=1)
    
    ai_news = [
        {
            "title": "OpenAIç™¼å¸ƒæ–°ä¸€ä»£å¤šæ¨¡æ…‹æ¨¡å‹ï¼Œçªç ´è¦–è¦ºç†è§£é™åˆ¶",
            "source": "TechCrunch",
            "date": today.strftime("%Yå¹´%mæœˆ%dæ—¥"),
            "summary": "OpenAIä»Šæ—¥å®£å¸ƒæ¨å‡ºå…¨æ–°å¤šæ¨¡æ…‹AIæ¨¡å‹ï¼Œèƒ½å¤ åŒæ™‚è™•ç†æ–‡å­—ã€åœ–åƒã€éŸ³é »å’Œè¦–é »è¼¸å…¥ï¼Œåœ¨è¦–è¦ºç†è§£ä»»å‹™ä¸Šé”åˆ°äººé¡æ°´å¹³ã€‚æ–°æ¨¡å‹ç‰¹åˆ¥å¼·åŒ–äº†å°è¤‡é›œå ´æ™¯çš„ç†è§£èƒ½åŠ›ï¼Œä¸¦æ”¯æŒå¯¦æ™‚äº’å‹•å°è©±ã€‚",
            "key_points": [
                "æ”¯æŒæ–‡å­—ã€åœ–åƒã€éŸ³é »ã€è¦–é »å¤šæ¨¡æ…‹è¼¸å…¥",
                "è¦–è¦ºç†è§£èƒ½åŠ›é”åˆ°äººé¡æ°´å¹³",
                "å¯¦æ™‚äº’å‹•å°è©±åŠŸèƒ½",
                "ä¼æ¥­ç´šAPIå³å°‡é–‹æ”¾"
            ]
        },
        {
            "title": "Google DeepMindåœ¨è›‹ç™½è³ªæ‘ºç–Šé æ¸¬å–å¾—æ–°çªç ´",
            "source": "Nature",
            "date": yesterday.strftime("%Yå¹´%mæœˆ%dæ—¥"),
            "summary": "Google DeepMindç ”ç©¶åœ˜éšŠåœ¨è›‹ç™½è³ªçµæ§‹é æ¸¬é ˜åŸŸå–å¾—é‡å¤§é€²å±•ï¼Œå…¶æœ€æ–°AIæ¨¡å‹èƒ½å¤ åœ¨æ•¸ç§’å…§æº–ç¢ºé æ¸¬è¤‡é›œè›‹ç™½è³ªçš„ä¸‰ç¶­çµæ§‹ï¼Œæº–ç¢ºç‡è¶…é95%ã€‚é€™é …çªç ´æœ‰æœ›åŠ é€Ÿæ–°è—¥é–‹ç™¼å’Œç–¾ç—…ç ”ç©¶ã€‚",
            "key_points": [
                "è›‹ç™½è³ªçµæ§‹é æ¸¬æº–ç¢ºç‡è¶…é95%",
                "é æ¸¬æ™‚é–“å¾æ•¸å°æ™‚ç¸®çŸ­åˆ°æ•¸ç§’",
                "å¯è™•ç†æœ€è¤‡é›œçš„è›‹ç™½è³ªçµæ§‹",
                "é–‹æºæ¨¡å‹ä¾›å­¸è¡“ç ”ç©¶ä½¿ç”¨"
            ]
        },
        {
            "title": "æ­ç›Ÿé€šéå…¨çƒé¦–å€‹å…¨é¢AIç›£ç®¡æ³•æ¡ˆ",
            "source": "Reuters",
            "date": today.strftime("%Yå¹´%mæœˆ%dæ—¥"),
            "summary": "æ­ç›Ÿè­°æœƒæ­£å¼é€šéã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹ï¼Œæˆç‚ºå…¨çƒé¦–å€‹å…¨é¢ç›£ç®¡AIæŠ€è¡“çš„æ³•å¾‹æ¡†æ¶ã€‚æ³•æ¡ˆæ ¹æ“šAIç³»çµ±çš„é¢¨éšªç­‰ç´šé€²è¡Œåˆ†é¡ç›£ç®¡ï¼Œç¦æ­¢æŸäº›é«˜é¢¨éšªæ‡‰ç”¨ï¼Œä¸¦å°ç”Ÿæˆå¼AIå¯¦æ–½é€æ˜åº¦è¦æ±‚ã€‚",
            "key_points": [
                "å…¨çƒé¦–å€‹å…¨é¢AIç›£ç®¡æ³•æ¡ˆ",
                "æ ¹æ“šé¢¨éšªç­‰ç´šåˆ†é¡ç›£ç®¡",
                "ç¦æ­¢æŸäº›é«˜é¢¨éšªAIæ‡‰ç”¨",
                "ç”Ÿæˆå¼AIéœ€æ¨™æ˜å…§å®¹ä¾†æº"
            ]
        }
    ]
    
    print(f"âœ… ç²å–åˆ° {len(ai_news)} æ¢AIæ–°è")
    return ai_news

def update_ai_news_page(news_items):
    """æ›´æ–°AIè³‡è¨Šé é¢"""
    
    print(f"æ­£åœ¨æ›´æ–°AIè³‡è¨Šé é¢: {AI_NEWS_FILE}")
    
    if not AI_NEWS_FILE.exists():
        print(f"éŒ¯èª¤: æ‰¾ä¸åˆ°æ–‡ä»¶ {AI_NEWS_FILE}")
        return False
    
    try:
        with open(AI_NEWS_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ç²å–ç•¶å‰æ—¥æœŸ
        today_chinese = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        today_iso = datetime.now().strftime("%Y-%m-%d")
        
        # 1. æ›´æ–°æœ€å¾Œæ›´æ–°æ™‚é–“
        update_pattern = r'<div class="update-time">æœ€å¾Œæ›´æ–°ï¼š\d{4} å¹´ \d{1,2} æœˆ \d{1,2} æ—¥</div>'
        new_update_div = f'<div class="update-time">æœ€å¾Œæ›´æ–°ï¼š{today_chinese}</div>'
        
        content = re.sub(update_pattern, new_update_div, content)
        print(f"âœ… å·²æ›´æ–°æ™‚é–“æˆ³")
        
        # 2. æ›´æ–°highlightå€åŸŸ
        highlight_pattern = r'<div class="highlight">(.*?)</div>'
        highlight_match = re.search(highlight_pattern, content, re.DOTALL)
        
        if highlight_match:
            highlight_content = highlight_match.group(1)
            
            # æ›´æ–°highlightä¸­çš„æ›´æ–°æ‘˜è¦
            update_summary_pattern = r'<strong>ğŸ“ \d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥æ›´æ–°ï¼š</strong>.*?(?=<br><br>|$)'
            
            if re.search(update_summary_pattern, highlight_content, re.DOTALL):
                # æ›¿æ›ç¾æœ‰çš„æ›´æ–°æ‘˜è¦
                latest_news_summary = f"OpenAIç™¼å¸ƒæ–°ä¸€ä»£å¤šæ¨¡æ…‹æ¨¡å‹ï¼ŒGoogle DeepMindåœ¨è›‹ç™½è³ªæ‘ºç–Šé æ¸¬å–å¾—çªç ´ï¼Œæ­ç›Ÿé€šéå…¨çƒé¦–å€‹å…¨é¢AIç›£ç®¡æ³•æ¡ˆã€‚"
                
                new_summary = f'<strong>ğŸ“ {today_chinese}æ›´æ–°ï¼š</strong> {latest_news_summary}'
                new_highlight = re.sub(update_summary_pattern, new_summary, highlight_content, flags=re.DOTALL)
                
                # æ›¿æ›æ•´å€‹highlightå€åŸŸ
                new_div = f'<div class="highlight">\n{new_highlight}\n</div>'
                content = content.replace(highlight_match.group(0), new_div)
                
                print(f"âœ… å·²æ›´æ–°highlightå€åŸŸ")
        
        # 3. æ›´æ–°æ–°èæ¨™é¡Œæ—¥æœŸ
        news_title_pattern = r'<h2>ğŸ—ï¸ æœ€æ–° AI æ–°è \(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥\)</h2>'
        new_news_title = f'<h2>ğŸ—ï¸ æœ€æ–° AI æ–°è ({today_chinese})</h2>'
        
        content = re.sub(news_title_pattern, new_news_title, content)
        print(f"âœ… å·²æ›´æ–°æ–°èæ¨™é¡Œæ—¥æœŸ")
        
        # 4. æ›´æ–°æ–°èå…§å®¹
        # æŸ¥æ‰¾ç¬¬ä¸€å€‹news-itemå€åŸŸ
        news_item_pattern = r'<article class="news-item">(.*?)</article>'
        news_items_matches = list(re.finditer(news_item_pattern, content, re.DOTALL))
        
        if news_items_matches and len(news_items_matches) >= 3:
            # æ›¿æ›å‰3å€‹æ–°èé …ç›®
            for i in range(min(3, len(news_items))):
                news_item = news_items[i]
                old_news_item = news_items_matches[i].group(0)
                
                # æ§‹å»ºæ–°çš„æ–°èé …ç›®
                new_news_item = f'''<article class="news-item">
        <h3>âš¡ {news_item["title"]}</h3>
        <p class="news-date">Source: {news_item["source"]} | {news_item["date"]}</p>
        <p>{news_item["summary"]}</p>
        
        <h4>ğŸ” é—œæ³¨é‡é»</h4>
        <ul>
'''
                
                # æ·»åŠ é—œéµé»
                for point in news_item["key_points"]:
                    new_news_item += f'            <li>{point}</li>\n'
                
                new_news_item += '''        </ul>
    </article>'''
                
                # æ›¿æ›æ–°èé …ç›®
                content = content.replace(old_news_item, new_news_item)
            
            print(f"âœ… å·²æ›´æ–° {min(3, len(news_items))} æ¢æ–°èå…§å®¹")
        
        # 5. æ›´æ–°Debate Modeéƒ¨åˆ†æ—¥æœŸ
        debate_pattern = r'<h2>ğŸ¯ Debate Modeï¼šå°ˆå®¶åˆ†æ \(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥\)</h2>'
        if re.search(debate_pattern, content):
            new_debate_title = f'<h2>ğŸ¯ Debate Modeï¼šå°ˆå®¶åˆ†æ ({today_chinese})</h2>'
            content = re.sub(debate_pattern, new_debate_title, content)
            print(f"âœ… å·²æ›´æ–°Debate Modeæ—¥æœŸ")
        
        # 6. æ·»åŠ ä»Šæ—¥AIè¶¨å‹¢åˆ†æ
        # åœ¨æ–°èéƒ¨åˆ†å¾Œæ·»åŠ ä»Šæ—¥åˆ†æ
        news_section_end_pattern = r'</article>\s*</div>'
        news_section_end_match = re.search(news_section_end_pattern, content, re.DOTALL)
        
        if news_section_end_match and 'ä»Šæ—¥AIè¶¨å‹¢åˆ†æ' not in content:
            today_analysis = f'''
    </article>
</div>

<div class="guide-section" style="margin-top: 30px; background-color: #f8f9fa; padding: 20px; border-radius: 10px; border-left: 5px solid #6f42c1;">
    <h2 style="color: #6f42c1; margin-top: 0;">ğŸš€ ä»Šæ—¥AIè¶¨å‹¢åˆ†æ ({today_chinese})</h2>
    
    <div class="trend-analysis">
        <h3>ğŸ“Š ç•¶å‰AIç™¼å±•è¶¨å‹¢</h3>
        <ul>
            <li><strong>å¤šæ¨¡æ…‹èåˆï¼š</strong> æ–‡å­—ã€åœ–åƒã€éŸ³é »ã€è¦–é »çš„å¤šæ¨¡æ…‹AIæˆç‚ºä¸»æµæ–¹å‘</li>
            <li><strong>å°ˆæ¥­é ˜åŸŸæ‡‰ç”¨ï¼š</strong> AIåœ¨é†«ç™‚ã€ç§‘å­¸ç ”ç©¶ç­‰å°ˆæ¥­é ˜åŸŸå–å¾—çªç ´æ€§é€²å±•</li>
            <li><strong>ç›£ç®¡æ¡†æ¶å»ºç«‹ï¼š</strong> å…¨çƒå„åœ‹åŠ é€ŸAIç›£ç®¡ç«‹æ³•é€²ç¨‹</li>
            <li><strong>é–‹æºç”Ÿæ…‹ç™¼å±•ï¼š</strong> é–‹æºAIæ¨¡å‹å’Œå·¥å…·ç”Ÿæ…‹ç³»çµ±æ—¥è¶¨æˆç†Ÿ</li>
        </ul>
        
        <h3>ğŸ¯ æŠ€è¡“ç™¼å±•é‡é»</h3>
        <ul>
            <li>å¼·åŒ–å­¸ç¿’åœ¨è¤‡é›œæ±ºç­–ä»»å‹™ä¸­çš„æ‡‰ç”¨</li>
            <li>å°æ¨£æœ¬å­¸ç¿’å’Œé·ç§»å­¸ç¿’æŠ€è¡“çš„æ”¹é€²</li>
            <li>AIç³»çµ±çš„å¯è§£é‡‹æ€§å’Œé€æ˜åº¦æå‡</li>
            <li>é‚Šç·£è¨ˆç®—å’Œè¼•é‡åŒ–AIæ¨¡å‹çš„ç™¼å±•</li>
        </ul>
        
        <p style="font-size: 0.9em; color: #666; margin-top: 15px;">
            <i class="fas fa-chart-line"></i> ä»¥ä¸Šåˆ†æåŸºæ–¼æœ€æ–°AIç ”ç©¶æ–‡ç»å’Œè¡Œæ¥­å‹•æ…‹
        </p>
    </div>
</div>
'''
            
            # åœ¨æœ€å¾Œä¸€å€‹æ–°èé …ç›®å¾Œæ’å…¥
            position = news_section_end_match.end()
            content = content[:position] + today_analysis + content[position:]
            
            print(f"âœ… å·²æ·»åŠ ä»Šæ—¥AIè¶¨å‹¢åˆ†æ")
        
        # ä¿å­˜æ›´æ–°å¾Œçš„æ–‡ä»¶
        with open(AI_NEWS_FILE, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"âœ… AIè³‡è¨Šé é¢æ›´æ–°å®Œæˆï¼")
        print(f"   æ›´æ–°æ™‚é–“: {today_chinese}")
        print(f"   æ–°å¢æ–°è: {len(news_items)} æ¢")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ›´æ–°å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•¸"""
    
    print("é–‹å§‹æ›´æ–°AIè³‡è¨Šé é¢...")
    
    # ç²å–æœ€æ–°AIæ–°è
    ai_news = fetch_ai_news()
    
    # æ›´æ–°é é¢å…§å®¹
    success = update_ai_news_page(ai_news)
    
    if success:
        print("âœ… AIè³‡è¨Šé é¢æ›´æ–°æµç¨‹å®Œæˆ")
        return 0
    else:
        print("âŒ AIè³‡è¨Šé é¢æ›´æ–°å¤±æ•—")
        return 1

if __name__ == "__main__":
    sys.exit(main())